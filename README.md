# AI Test Suite Analyzer

> Automated test case quality analysis using OpenAI GPT-4o-mini - Analyze 56 test cases for $0.001

An intelligent test analysis tool that reads Excel test cases, evaluates quality using AI, and generates comprehensive reports with actionable insights.

---

## ğŸ¯ Problem Statement

Manual test case review is:
- â° **Time-consuming**: 5-10 minutes per test case
- ğŸ‘ï¸ **Inconsistent**: Quality varies by reviewer
- ğŸ“ˆ **Not scalable**: Impossible to review 500+ test cases regularly
- ğŸ’¼ **Expensive**: Senior QA time costs $50-100/hour

**This tool solves that.**

---

## âœ¨ Features

### Core Capabilities
- ğŸ“Š **AI-Powered Analysis**: Uses GPT-4o-mini to evaluate test quality
- ğŸ“ˆ **Multi-Sheet Excel Output**: Separate sheets for detailed analysis, issues, and statistics
- âš¡ **Real-Time Progress**: Visual progress bar with ETA calculation
- ğŸ’° **Cost-Optimized**: 84% token reduction through prompt engineering ($0.001 for 56 tests)
- ğŸ¨ **Color-Coded Feedback**: Green for good tests, orange for issues, red for errors
- ğŸ“‹ **Actionable Insights**: Specific, concise improvement suggestions

### Output Sheets
1. **AI Detailed Analysis**: Original test cases with AI feedback column
2. **Quality Issues Summary**: Filtered list of tests needing improvement
3. **Statistics Dashboard**: Executive-level metrics and recommendations

### Quality Checks
- âœ… Test completeness (preconditions, steps, expected results)
- âœ… Clarity and specificity
- âœ… Best practices compliance
- âœ… Missing error scenarios
- âœ… Boundary condition coverage

---

## ğŸ“¸ Screenshots

### Real-Time Progress Bar
```
[============>.......] 67.9% | 38/56 | TC-038 | ETA: 35s
```

### Sample Output
Multi-sheet Excel file with:
- AI Detailed Analysis (color-coded feedback)
- Quality Issues Summary (actionable list)
- Statistics Dashboard (executive metrics)

---

## ğŸ—ï¸ Architecture
```
Excel Input â†’ AI Test Analyzer â†’ OpenAI API â†’ Analysis Engine â†’ Excel Output
                                                                      â†“
                                                          [3 Formatted Sheets]
```

**Processing Flow:**
1. Read test cases from Excel (EPPlus)
2. Send to OpenAI GPT-4o-mini for analysis
3. Parse and categorize AI feedback
4. Write results to multiple Excel sheets
5. Apply formatting and color coding
6. Generate statistics and recommendations

---

## ğŸ“¦ Installation

### Prerequisites
- Visual Studio 2022 (or later)
- .NET 10.0 SDK
- OpenAI API Key ([Get one here](https://platform.openai.com))

### Setup Steps

1. **Clone the repository**
```bash
   git clone https://github.com/arvindhanqa/ai-test-suite-analyzer.git
   cd ai-test-suite-analyzer
```

2. **Configure API Key**
   
   Edit `src/AITestAnalyzer/appsettings.json`:
```json
   {
     "OpenAI": {
       "ApiKey": "YOUR-API-KEY-HERE",
       "Model": "gpt-4o-mini"
     },
     "Excel": {
       "FilePath": "../../data/test_cases_shopease.xlsx"
     }
   }
```

3. **Install Dependencies**
```bash
   cd src/AITestAnalyzer
   dotnet restore
```

4. **Build**
```bash
   dotnet build
```

---

## ğŸš€ Usage

### Quick Start

1. **Prepare your Excel file** with columns:
   - Test ID | Feature | Scenario | Priority | Steps | Expected Result | Status

2. **Update configuration** in `appsettings.json`:
   - Set your OpenAI API key
   - Point to your Excel file path

3. **Run the analyzer**
```bash
   dotnet run
```

4. **Find results** in `output/` folder:
   - `analysis_results_YYYYMMDD_HHMMSS.xlsx`

### Sample Output
```
AI Test Suite Analyzer - Week 1
===============================================

ğŸ“‹ Loading configuration...
   âœ… Model: gpt-4o-mini
   âœ… Max Tokens: 150

ğŸ“ Preparing output file...
   âœ… Output file: analysis_results_20260126_133111.xlsx

ğŸ“Š Analyzing 56 test cases...
   [====================] 100.0% | 56/56 | TC-056 | ETA: 0s
   âœ… Analysis complete!

===============================================
ğŸ“Š ANALYSIS SUMMARY
===============================================
Tests analyzed: 56
âœ… Good tests: 3 (5%)
âš ï¸  Tests with issues: 53 (95%)

Total tokens: 6,932
Total cost: $0.001040
Avg tokens/test: 123
â±ï¸  Time: 150.2 seconds

ğŸ“ Output: analysis_results_20260126_133111.xlsx
===============================================
```

---

## ğŸ’° Cost Analysis

### Actual Performance (56 Tests)
- **Total tokens**: 6,932
- **Total cost**: $0.001040
- **Cost per test**: $0.000019
- **Time**: 150 seconds (~2.7 sec/test)

### Optimization Journey
| Iteration | Tokens/Test | Cost/56 Tests | Savings |
|-----------|-------------|---------------|---------|
| Initial   | 750         | $0.0063       | -       |
| Optimized | 184         | $0.0015       | 75%     |
| Final     | 123         | $0.001        | 84%     |

### Budget Projections
- **$10 budget**: ~555,000 test analyses
- **500 tests**: $0.0093
- **1,000 tests**: $0.0186
- **Annual (4 runs x 500 tests)**: $0.037

**Result**: Cost is negligible for realistic usage.

---

## ğŸ› ï¸ Technology Stack

- **Language**: C# (.NET 10.0)
- **Excel Processing**: EPPlus 7.x
- **AI Integration**: Betalgo.OpenAI 8.7.2
- **AI Model**: OpenAI GPT-4o-mini
- **Configuration**: Microsoft.Extensions.Configuration
- **Platform**: Windows 10/11

---

## ğŸ“‹ Project Structure
```
ai-test-suite-analyzer/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ AITestAnalyzer/
â”‚       â”œâ”€â”€ Program.cs                 # Main application logic
â”‚       â”œâ”€â”€ Configuration.cs           # App configuration class
â”‚       â”œâ”€â”€ PromptConfig.cs           # AI prompt configuration
â”‚       â”œâ”€â”€ TestCase.cs               # Test case model
â”‚       â”œâ”€â”€ appsettings.json          # App settings (API key)
â”‚       â””â”€â”€ PromptConfig.json         # Prompt templates
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ requirements_shopease.md      # Sample requirements
â”‚   â””â”€â”€ test_cases_shopease.xlsx      # Sample test cases
â”œâ”€â”€ output/                            # Generated analysis reports
â””â”€â”€ README.md
```

---

## ğŸ¯ Roadmap

### Week 1 (Current) âœ…
- [x] Multi-sheet Excel output
- [x] Real-time progress bar
- [x] Statistics dashboard
- [x] Cost optimization (84% reduction)

### Weeks 5-8 (Planned)
- [ ] **Coverage Gap Analysis**: Compare tests against requirements
- [ ] **Flow Correctness Validation**: Verify test steps match requirement flows
- [ ] **Step Completeness Check**: Ensure all validation steps present

### Future Enhancements
- [ ] Batch processing (multiple Excel files)
- [ ] Command-line arguments
- [ ] Configurable test count
- [ ] Export to PDF/HTML
- [ ] Integration with JIRA/TestRail

---

## ğŸ“Š Results

### Test Quality Distribution (Sample 56 Tests)
- **Good Quality**: 3 tests (5.4%)
- **Need Improvement**: 53 tests (94.6%)

### Common Issues Found
- Missing expected result details (42%)
- Vague test steps (31%)
- No error scenario coverage (18%)
- Unclear validation criteria (9%)

**AI correctly identified intentionally poor test cases with specific, actionable feedback.**

---

## ğŸ‘¤ Author

**Aravindhan Rajasekaran**
- **Current Role**: Lead Test Engineer @ Acumatica (2020-Present)
- **Experience**: 10+ years in QA, Test Automation, and Software Development
- **Expertise**: C#, Java, Python, Selenium, API Testing, CI/CD
- **Certifications**: ISTQB Certified, Certified Scrum Master
- **GitHub**: [@arvindhanqa](https://github.com/arvindhanqa)
- **LinkedIn**: [linkedin.com/in/aravindrajsekar](https://www.linkedin.com/in/aravindrajsekar)
- **Location**: Saskatoon, Saskatchewan, Canada

### Notable Achievements
- ğŸ† Increased test automation coverage from 15% to 95% (3,000 automated tests)
- ğŸ† Reduced production bugs from 50 to 5 per month through Test SOP implementation
- ğŸ† Led distributed QA teams across USA, Serbia, and Sri Lanka
- ğŸ† Created in-house test coverage calculator tool
- ğŸ† Automated 500+ scenarios for 22 new features with 100% coverage

---

## ğŸ¤ About This Project

This is a personal learning project built as part of a 90-day commitment (January 20 - April 19, 2026) to:
1. Break a 20-year pattern of unfinished projects
2. Build practical AI-powered tooling
3. Demonstrate ability to ship complete software from concept to production

**Status (Day 8)**: On schedule. Tool is production-ready and delivering value.

---

## ğŸ“ License

MIT License - Feel free to use and modify for your own projects.

---

**â­ If you find this useful, please star the repository!**